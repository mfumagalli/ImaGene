{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using _ImaGene_\n",
    "\n",
    "In this exercise you will learn how to perform a multiclass classification using _ImaGene_.\n",
    "In this example, your goal is to classify whether a given _locus_ is under positive selection or neutrally evolving with 3 classes of selection coefficient (0,200,400 in $2N_e$ units with $N_e=10000$).\n",
    "\n",
    "You will be using the case of lactase persistence in European populations following the data and example of `01_binary` notebook.\n",
    "Please refer to the tutorial for binary classification for an in-depth explanation of the case study and help on the main steps of the pipeline.\n",
    "Here you will also learn the main differences with the case of binary classification.\n",
    "Your job is to fill in lines with `# ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import _pickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import arviz\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers, activations, optimizers, regularizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import itertools\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydot # optional, but required by keras to plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../ImaGene.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data from VCF file and store it into _ImaGene_ objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_LCT = ImaFile(nr_samples=198, VCF_file_name='LCT.CEU.vcf')\n",
    "gene_LCT = file_LCT.read_VCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume we are unsure about the ancestral/derived polarisation and we switch labelling of alleles to major/minor.\n",
    "We also then retain all polymorphic sites and discard columns corresponding to sites with a sample minor allele frequency of 0 (e.g., a suitable threshold is 0.005 which is < 1/198)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the data processing explained above\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dimensions and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.summary();\n",
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, we order rows based on their genetic distance from the most frequent haplotype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... hint: check help page gene_LCT.sort?\n",
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run and process simulations to be used for training the neural network\n",
    "\n",
    "We provide an example of parameter file called `params_multiclass` which simulates a total of 250,000 loci of 80kbp either under neutral evolution or positive selection with additive effect and allelic selection coefficients of 100, 200, 300, or 400 in $2N_e$ units with $N_e=10,000$.\n",
    "All other parameters are set as in the example of binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as appropriate, e.g.:\n",
    "# path_sim='/home/mfumagal/Data/ImaGene/Tutorials/' # my local machine\n",
    "# path_sim='/mnt/quobyte/ImaGene/' # for workshop spp1819\n",
    "path_sim = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open, edit, save and class `params_multiclass.txt` file to specify directories and simulation parameters. Here I assume that simulations will be stored in `path+Multiclass/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wish to generate new training data, do not run otherwise\n",
    "import subprocess\n",
    "subprocess.call(\"bash ../generate_dataset.sh params_multiclass.txt\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, read the first batch of simulations to explore their content. Retain only 200 data points per class for a quick example (or even less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing value ...\n",
    "file_sim = ImaFile(simulations_folder=path_sim + 'Multiclass/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');\n",
    "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=...);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we have 1000 images (if you used 200 for each one of the 5 classes).\n",
    "The average number of columns is $\\approx ...$\n",
    "\n",
    "We can check the sample allele frequency for the selected allele. Recall that we imposed selection to be acting in the middle of the region. Therefore, the targeted allele will be in position '0.5' in the _msms_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = calculate_allele_frequency(gene_sim, 0.5);\n",
    "plt.scatter(gene_sim.targets, freqs, marker='o');\n",
    "plt.xlabel('Selection coefficient');\n",
    "plt.ylabel('Allele frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same data processing as done for LCT. As an example, we resize all images to the average dimensions of (198,285)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to switch to major/minor, filter based on allele frequencies, sort rows and resize\n",
    "# ...\n",
    "# remember to add `gene_sim.convert();` at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we are just interested in a classification of 3 classes: 0, 200, 400.\n",
    "For doing that, first we need to set `.classes` to the desired values and then we need to take a subset of the data corresponding to the desired classes only.\n",
    "We can achieve these steps with the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.classes = np.array([0,200,400]);\n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many data points you have?\n",
    "\n",
    "We now have 600 data points corresponding to the desired classes, as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement, train and evaluate the neural network\n",
    "\n",
    "As discussed in the tutorial on binary classification, we need to repeat this procedure across all batches of data leaving the last one for testing. We retain 1000 images per class as an illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in all missing values (...) or lines\n",
    "i = 1\n",
    "while i <= 10:\n",
    "\n",
    "    # simluations \n",
    "    file_sim = ImaFile(simulations_folder=path_sim+'Multiclass/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
    "\n",
    "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=...)\n",
    "    \n",
    "    # manipulate data:\n",
    "    # switch to major/minor allele polarisation\n",
    "    # filter our monomorphic sites\n",
    "    # sort rows by genetic distance\n",
    "    # ...\n",
    "    # ...\n",
    "    # ...\n",
    "    # ...\n",
    "    gene_sim.convert()\n",
    "    \n",
    "    # use only classes 0,200,400\n",
    "    gene_sim.classes = np.array([0,200,400])\n",
    "    gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes))\n",
    "\n",
    "    # randomise data\n",
    "    gene_sim.subset(get_index_random(gene_sim))\n",
    "\n",
    "    # convert targets to categorical data\n",
    "    gene_sim.targets = to_categorical(gene_sim.targets)\n",
    "    \n",
    "    # at first iteration we build the model \n",
    "    if i == 1:\n",
    "\n",
    "        model = models.Sequential([ # build your network! you can use a similar architecture to the binary case\n",
    "                    # ...\n",
    "                    # ...\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(units=128, activation='relu'),\n",
    "                    # for the last dense layer, how many output units do you have? also, what is the activation function?\n",
    "                    layers.Dense(units=..., activation=...)])\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='...', # which loss do you need? check https://keras.io/api/losses/probabilistic_losses/#categorical_crossentropy-function\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        net_LCT = ImaNet(name='[C32+P]+[C64+P]x2+D128') # name is not really important\n",
    "\n",
    "    # training for iterations from 1 to 9\n",
    "    if i < 10:\n",
    "        score = model.fit(gene_sim.data, gene_sim.targets, batch_size=32, epochs=1, verbose=0, validation_split=0.10)\n",
    "        net_LCT.update_scores(score)\n",
    "    else:\n",
    "        # testing for iteration 10\n",
    "        net_LCT.test = ... \n",
    "        net_LCT.predict(...)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory where to save models, e.g. \n",
    "# path='/home/mfumagal/Data/ImaGene/Tutorials/Data/' # my local machine\n",
    "# path='./' # for workshop spp1819\n",
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just as an illustration....\n",
    "# save final (trained) model\n",
    "model.save(path+'model.multi.h5');\n",
    "\n",
    "# save testing data\n",
    "gene_sim.save(path+'gene_sim.multi');\n",
    "\n",
    "# save network\n",
    "net_LCT.save(path+'net_LCT.multi');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just as an illustration....\n",
    "# load the objects above\n",
    "model = load_model(path+'model.multi.h5');\n",
    "gene_sim = load_imagene(file=path+'gene_sim.multi');\n",
    "net_LCT = load_imanet(path+'net_LCT.multi');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the training, plot loss and accuracy over epochs\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the testing results [loss, accuracy]\n",
    "print(net_LCT.test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a confusion matrix (on the last gene_sim object which represents the testing data)\n",
    "net_LCT.#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusions can you make from the assessment of the training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy the trained network on your genomic data of interest\n",
    "\n",
    "Finally we use the trained network to predict the class of natural selection on our locus of interest.\n",
    "First we need to resize our real data to match the data used for training.\n",
    "After that, we need to convert the data into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... resize...\n",
    "gene_LCT.convert();\n",
    "gene_LCT.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(gene_LCT.data, batch_size=None));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the output of the command above?  What do these values mean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
