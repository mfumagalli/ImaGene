{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting selection with deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples and exercises using _keras_ and _ImaGene_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "\n",
    "In this practical our aim is to predict whether a given locus is under natural selection, specifically positive selection. from population genomic data. \n",
    "We will implement a deep learning algorithm to this aim, and use [_keras_](https://keras.io/) for implementing the network and [_ImaGene_](https://github.com/mfumagalli/ImaGene) for manipulating data. Both are accessible through _python_.\n",
    "The goal of this exercise is not to learn how _ImaGene_ works but how you can manipulate genetic data and build simple algorithms and architectures in _keras_.\n",
    "\n",
    "In the first example, we will perform a **binary classification** on the classic example of positive selection for lactase persistence in human European populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Why lactase persistence? Why in Europeans?\n",
    "\n",
    "The C/T(-13910) variant, or rs4988235, is located on chromosome 2 in the _MCM6_ gene but influences the lactase _LCT_ gene. This SNP is associated with the primary haplotype associated with lactose intolerance in European populations. \n",
    "In these populations, the common T allele is associated with lactase persistence. Individuals who are homozygous for C allele are likely to be lactose intolerant. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "We extracted SNP information from a region of 80k base pairs around the target variant rs4988235 from the 1000 Genomes Project data for all unrelated individuals of CEU population (of European descent).\n",
    "The data is in the form of a VCF file.\n",
    "\n",
    "In this practical, you will learn how to:\n",
    "1. read data from VCF file and store it into _python_ objects,\n",
    "2. process simulations to be used for training,\n",
    "3. implement, train and evaluate a neural network,\n",
    "4. deploy the trained network on your genomic data of interest.\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "\n",
    "The first part is a guided exercise to perform a simple task. In this way, you will learn how to build models in _keras_ and use _ImaGene_ to manipulate data.\n",
    "In the second part, you will be asked to perform more complex tasks and fill in the missing bits in the code to perform such task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided exercise\n",
    "\n",
    "We need to load the necessary modules in _python_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mfumagalli/ImaGene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import _pickle as pickle\n",
    "\n",
    "import numpy as np # actual haplotype data is stored as numpy arrays\n",
    "import scipy.stats\n",
    "import arviz\n",
    "\n",
    "import tensorflow as tf # we will be using keras with tensorflow as backend\n",
    "from tensorflow import keras\n",
    "from keras import models, layers, activations, optimizers, regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt # for plotting purposes\n",
    "import skimage.transform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%run -i /content/ImaGene/ImaGene.py # functions to manipulate VCF and simulation files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data from VCF file and store it into _ImaGene_ objects\n",
    "\n",
    "We store the information of the genomic data into an _ImaFile_ object where we specify the name of the VCF file and the number of samples (i.e. the number of chromosomal copies, twice the number of individuals for a diploid organism).\n",
    "The latter parameter is not strictly necessary but it is useful to check whether the VCF we are analysing contains the data that we expect.\n",
    "\n",
    "In the example below, we load 198 haplotypes (from 99 human diploid samples) from the 'LCT.CEU.vcf' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_LCT = ImaFile(nr_samples=198, VCF_file_name='/content/ImaGene/Tutorials/LCT.CEU.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an _ImaGene_ object by reading the VCF file and generating a matrix of haplotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT = file_LCT.read_VCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An _ImaGene_ object has a series of useful methods that can be visualised with `gene_LCT.` and press ctrl+space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_LCT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can have a quick look at the data stored in this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we have one image with 198 rows (equivalent to the number of sampled chromosomal copies) and 2200 columns representing all genomic positions reported.\n",
    "It is likely that not all of these positions will be polymorphic in the CEU sample as the VCF file reports variats across all analysed populations.\n",
    "\n",
    "Similarly, we may want to discard rare variants as they may be more associated to errors or be less informative of the scenario we want to predict.\n",
    "Assume that we want to ignore monomorphic sites and singletons for the derived allele.\n",
    "We can accomplish this with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.filter_freq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.filter_freq(0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are unsure about the ancestral/derived polarisation of alleles, we can convert them into major/minor alleles using the method `.majorminor()`. \n",
    "We can have a look at the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the order on the rows is arbitrary, we can order them (and columns) following several criteria.\n",
    "We can do this with _ImaGene_ with the `.sort` method which has the following options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.sort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we wish to sort only rows by their frequency (with the most frequent haplotypes on the top).\n",
    "This can be done with the following command (which will also visualise the resulting image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.sort('rows_freq');\n",
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are happy with our data processing (e.g. filtering and sorting), we need to convert the image into an appropriate format which will be later used for the prediction.\n",
    "As an illustration, we also flip black and white pixels to assign the former to derived (or minor) alleles which is the standard representation of genomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.convert(flip=True); # this step is mandatory, don't ask why!\n",
    "gene_LCT.plot();\n",
    "gene_LCT.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally note that our image has 192 columns now, representing the number of retained SNPs.\n",
    "\n",
    "We can save our _ImaGene_ object in the working `path = './'` directory with `gene_LCT.save(file=path + 'gene_LCT');`.\n",
    "As a further illustration, the following line `gene_LCT = load_imagene(file=path + 'gene_LCT')` will load the _ImaGene_ object from a saved file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process simulations to be used for training the neural network\n",
    "\n",
    "_ImaGene_ provides users with an easy interface with [_msms_](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2916717/) to run simulations which will be used for training the network.\n",
    "However, we already provide simulations a total of \n",
    "loci of 80kbp either under neutral evolution or positive selection with additive effect and an allelic selection coefficient of either $0.75$\\% and $1.5$\\% targeting a variant in the middle of the region.\n",
    "We imposed that selection starts 800 generations ago (corresponding to 20kya with a generation time of 25 years) with an allele frequency of $0.01$.\n",
    "\n",
    "We impose a mutation rate is $1.5e-8$ per base per generation and a recombination rate of $1e-8$.\n",
    "Finally, the simulated population follows a 3-epoch model of bottleneck and expansion as proposed by [Marth et al. 2004](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1470693/) for a European population.\n",
    "We sampled 198 chromosomal copies to match our observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wish to generate new training data, do not run otherwise\n",
    "# import subprocess\n",
    "# subprocess.call(\"bash ../../generate_dataset.sh params_workshop.txt\".split());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process these simulations to be then fed as training data to our algorithm.\n",
    "To do that, we need to read and store simulations into an _ImaFile_ object.\n",
    "\n",
    "You can download a `tar.xz` file with these simulations from `https://drive.google.com/file/d/18T_ryHihKwNCdgRnNbPg05TIzHG994NV/view?usp=sharing`.\n",
    "Copy it in your Google Drive landing page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvf /content/drive/MyDrive/Data.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will split the simulation folder into different batches to later perform training with a (pseudo)-simulation-on-the-fly approach.\n",
    "\n",
    "Specifically, we simulate 20 different batches (folders) of simulations 1-20:\n",
    "\n",
    "| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | ... | 19 | 20 |\n",
    "\n",
    "Each batch (folder) contains 400 simulations. We reserve the last one (nr 20) for testing. We will go over the training on batch 1 as an example, and then run training on 2-19 batches in a more automated way. We will reserve a proportion of simulations within each batch for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the first iteration of training on the first batch of simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sim = ImaFile(simulations_folder='Data/Simulations1', nr_samples=198, model_name='Europe');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we populate an _ImaGene_ object by specifying the variable we want to estimate/predict (`selection_coeff_hetero`) and how many data points per class we wish to retain. \n",
    "As a quick example, we will use only 200 data points per class. You can use up to 400 data points in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=200);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the data stored in this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 600 images in this object. Recall that with the first line we simulated 3 classes and retained 200 data points for each class. All images have 198 rows as expected, as this represents the number of simulated haplotypes. However, images have different number of columns, ranging from $143$ to $434$ with an average value of around $290$. The number of columns represents the number of polymorphic sites and fixed derived alleles in a _msms_ file. This number may vary from one simulated gene to another.\n",
    "Our observed data for LCT has 192 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the sample allele frequency for the selected allele. Recall that we imposed selection to be acting in the middle of the region. Therefore, the targeted allele will be in position '0.5' in the _msms_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = calculate_allele_frequency(gene_sim, 0.5);\n",
    "plt.scatter(gene_sim.targets, freqs, marker='o');\n",
    "plt.xlabel('Selection coefficient');\n",
    "plt.ylabel('Allele frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, _ImaGene_ provides functionalities to manipulate our data. Specifically we can do the following:\n",
    "* convert ancestral/derived to major/minor allele polarisation\n",
    "* filter out columns based on a minimum allele frequency (e.g. 0.01)\n",
    "* sorting rows and columns by frequency (or genetic distance from the most frequent entry)\n",
    "\n",
    "We need to follow the same data processing as the one employed for the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.filter_freq(0.01);\n",
    "gene_sim.sort('rows_freq');\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images must have the same dimensions. You can explore all different options for resizing as alternative solutions to padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gene_sim.resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gene_sim.crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possibility would be to resize them to match the dimensions of the real data.\n",
    "In this case it means resize all images to have shape (198, 192) which can be achieved with either of the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing\n",
    "# gene_sim.resize((198, 192));\n",
    "# gene_sim.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.crop(192);\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data manipulation is done, we need to convert images to proper _numpy_ float matrices, as previously discussed. The following line will do the job (including flipping black/white pixels). \n",
    "Note that the `.convert` method allows you to normalise the data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.convert(flip=True);\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in addition to the genomic data, an _ImaGene_ object contains information on the corresponding targets (in this case the selection coefficient, either 0, 150, or 300 in $2N_e$ units with $N_e = 10000$).\n",
    "As an illustration, let's plot one random image per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in gene_sim.classes:\n",
    "    print(sel)\n",
    "    gene_sim.plot(np.where(gene_sim.targets == sel)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this guided example, we just assume to have 2 classes, either neutrality (0) or strong selection (300)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.classes = np.array([0,300]);\n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to randomly shuffle our images before using them for training our network.\n",
    "We can easily accomplish this with the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.subset(get_index_random(gene_sim));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our targets represent the 2 possible classes. However, since we are doing a binary classification, we need to vectorise them as required by _keras_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.targets = to_binary(gene_sim.targets);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object is now ready to be used for the classification!\n",
    "You can save it with `gene_sim.save(file=path + 'gene_sim.binary');`. If you want to load an _ImaGene_ object you can use the following function `gene_sim = load_imagene(file=path + 'gene_sim.binary');`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement, train and evaluate the neural network\n",
    "\n",
    "Now that our data is ready, we can build our network.\n",
    "Specifically, we can build a model in _keras_ with convolutional, pooling and dense layers.\n",
    "\n",
    "We will be using the [Sequential model](https://keras.io/guides/sequential_model/) which is \"very straightforward (a simple list of layers), but is limited to single-input, single-output stacks of layers (as the name gives away).\"\n",
    "\n",
    "The layers can be specified like described [here](https://keras.io/api/layers/).\n",
    "\n",
    "In this example we have 2 layers of [2D convolutions](https://keras.io/api/layers/convolution_layers/convolution2d/) and [2D pooling](https://keras.io/api/layers/pooling_layers/max_pooling2d/) followed by a fully-connected [dense](https://keras.io/api/layers/core_layers/dense/) layer.\n",
    "We just need to specify the dimensions of the data in the first layer, and this is specified by the option `input_shape=gene_sim.data.shape[1:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(units=128, activation='relu'),\n",
    "                    layers.Dense(units=1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's [compile](https://keras.io/api/models/model_training_apis/) our _keras_ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all loss functions is [here](https://keras.io/api/losses/).\n",
    "Let's look at a summary of the model. You can also plot it with `plot_model(model, path + 'net.binary.png')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for doing the training on this first batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.fit(gene_sim.data, gene_sim.targets, batch_size=32, epochs=1, verbose=1, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can save a _keras_ model with `model.save('net.h5')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialise a network object _ImaNet_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LCT = ImaNet(name='binary_task');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep track of scores (loss and accuracy) across iterations with `.update_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LCT.update_scores(score);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to repeat the whole procedure described above using all remaning batches of data, leaving the last one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "while i < 20:\n",
    "\n",
    "    print('batch: ' + str(i))\n",
    "    \n",
    "    file_sim = ImaFile(simulations_folder='Data/Simulations' + str(i), nr_samples=198, model_name='Europe')\n",
    "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=200)\n",
    "    \n",
    "    gene_sim.filter_freq(0.01)\n",
    "    gene_sim.sort('rows_freq')\n",
    "    gene_sim.crop(192)\n",
    "    gene_sim.convert(flip=True)\n",
    "\n",
    "    gene_sim.classes = np.array([0,300]); \n",
    "    gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "\n",
    "    gene_sim.subset(get_index_random(gene_sim))\n",
    "    gene_sim.targets = to_binary(gene_sim.targets)\n",
    "     \n",
    "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=32, epochs=1, verbose=1, validation_split=0.10)\n",
    "    net_LCT.update_scores(score)\n",
    "   \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot loss and validation accuracy during the training to check, for instance, for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LCT.plot_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save (and/or load) the final trained model with `model.save(path + 'model.binary.h5')` and `model = load_model(path + 'model.binary.h5')`.\n",
    "You can also save the network itself (and load it) with `net_LCT.save(path + 'net_LCT.binary');` and `net_LCT = load_imanet(path + 'net_LCT.binary')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the training on the testing dataset, i.e. the last batch of simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "file_sim = ImaFile(simulations_folder='Data/Simulations' + str(i), nr_samples=198, model_name='Europe')\n",
    "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=200)\n",
    "\n",
    "gene_sim.filter_freq(0.01)\n",
    "gene_sim.sort('rows_freq')\n",
    "gene_sim.crop(192)\n",
    "gene_sim.convert(flip=True)\n",
    "\n",
    "gene_sim.classes = np.array([0,300]); \n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "\n",
    "rnd_idx = get_index_random(gene_sim) # no need to create this extra variable\n",
    "gene_sim.subset(rnd_idx)\n",
    "\n",
    "gene_sim.targets = to_binary(gene_sim.targets);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's report loss and accuracy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LCT.test = model.evaluate(gene_sim.data, gene_sim.targets, batch_size=None, verbose=0)\n",
    "print(net_LCT.test) # it will report [loss, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a binary (or multiclass) classification, it is convenient to plot the confusion matrix after predicting the responses from the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_LCT.predict(gene_sim, model)\n",
    "net_LCT.plot_cm(gene_sim.classes, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy the trained network on your genomic data of interest\n",
    "\n",
    "Finally we can use the trained network to predict natural selection on our locus of interest.\n",
    "The output of this command will give us the class score (from 0 to 1) of said locus under positive selection under the conditions we simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(gene_LCT.data, batch_size=None)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOB (Build Your Own Best network)\n",
    "\n",
    "Now it's your turn to build your own deep learning algorithm to perform more challenging tasks: \n",
    "1. redo the above example of a binary classification [0, 300],\n",
    "2. a new binary classification [0, 150], or\n",
    "3. a multiclass classification [0, 150, 300].\n",
    "\n",
    "Be aware that in the latter case, loss and activation functions change. Check [keras](https://keras.io/) and the links provided in the guided example for the correct definition and setting of these parameters.\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "Few suggestions or directions you can take (in order of complexity):\n",
    "- use different filtering (`.filter_freq`), ordering (`.sort`), resizing (`.resize` or `.crop`), or allelic polarisation (`.majorminor`) options\n",
    "- change the capacity or depth of your network by modifying the number of layers, filters, dimension of kernels, padding, or regularization\n",
    "- implement a permutation-invariant function (e.g. with an AveragePooling layer) in combination with 1D convolution (or better phrased, as Conv2D with (1,x) dimensions)\n",
    "\n",
    "Don't forget to check for overfitting and, in case, add a [DropOut](https://keras.io/api/layers/regularization_layers/dropout/) or [BatchNormalisation](https://keras.io/api/layers/normalization_layers/batch_normalization/) layer or modify the hyper-parameters of regularisation).\n",
    "\n",
    "Calculate the testing accuracy **at the very end**, only once you are satisfied with your data processing and architecture. You can monitor interim performance with the validation accuracy.\n",
    "Remember that you can use up to 400 data points for each simulation batch.\n",
    "\n",
    "Feel free to work in pairs, groups or go solo, whatever suits you.\n",
    "I provide some help code so you can focus on only lines and parameters that matter.\n",
    "\n",
    "**Be creative and enjoy!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help code: model\n",
    "\n",
    "model = models.Sequential([\n",
    "                    layers....(filters=.., kernel_size=..., strides=..., activation='relu', kernel_regularizer=..., padding='valid', input_shape=(198,...,1)),\n",
    "                    ... # add/modify as you wish\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(units=..., activation='relu'),\n",
    "                    layers.Dense(units=..., activation=...)]) # what's the dimension of the final output? \n",
    "                    # what's the activation funtion of the final layer?\n",
    "\n",
    "model.compile(optimizer=..., # pick on\n",
    "              loss=..., # what is the loss function for multiclass classification?\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help code: training\n",
    "\n",
    "net_LCT = ImaNet(name='multiclass_task') # it simply initialises this object\n",
    "\n",
    "i = 1\n",
    "while i < 20: # loop from simulation batch 1 to 19, leave 20 for testing\n",
    "\n",
    "    print(i)\n",
    "    \n",
    "    file_sim = ImaFile(simulations_folder='Data/Simulations' + str(i), nr_samples=198, model_name='Europe') # mandatory\n",
    "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=...) # fill in nr of replicates per class you wish to retain\n",
    "    \n",
    "    gene_sim.... # filter/manipulate data as you wish\n",
    "    \n",
    "    gene_sim.resize((..., ...)) # or gene_sim.crop(...)\n",
    "    gene_sim.convert(flip=True) # mandatory\n",
    "\n",
    "    # if you use a subset of the simulations:\n",
    "    # for e.g. multiclass:\n",
    "    gene_sim.classes = np.array([0,150,300]); # change to np.array([0,300]) or np.array([0,150]) for binary classification  \n",
    "    \n",
    "    gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "        \n",
    "    gene_sim.subset(get_index_random(gene_sim)) # mandatory\n",
    "    \n",
    "    gene_sim.targets = to_binary(gene_sim.targets) # mandatory for binary classification\n",
    "    # or\n",
    "    gene_sim.targets = to_categorical(gene_sim.targets) # mandatory for multiclass: it converts to a suitable format\n",
    "     \n",
    "    score = model.fit(gene_sim.data, gene_sim.targets, batch_size=32, epochs=1, verbose=1, validation_split=...) # how much data do you wish to retain for validation\n",
    "    net_LCT.update_scores(score) # mandatory\n",
    "   \n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help code: testing\n",
    "\n",
    "i = 20\n",
    "file_sim = ImaFile(simulations_folder='Data/Simulations' + str(i), nr_samples=198, model_name='Europe')\n",
    "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=...)\n",
    "\n",
    "gene_sim....\n",
    "\n",
    "gene_sim.resize((..., ...)) # or gene_sim.crop(...)\n",
    "gene_sim.convert(flip=True) # mandatory\n",
    "\n",
    "gene_sim.classes = np.array([0,150,300]); # change np.array([...]) accordingly\n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "\n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes)) # mandatory\n",
    "\n",
    "gene_sim.targets = to_binary(gene_sim.targets) # mandatory for binary classification\n",
    "# or\n",
    "gene_sim.targets = to_categorical(gene_sim.targets) # mandatory for multiclass: it converts to a suitable format\n",
    "\n",
    "net_LCT.test = model.evaluate(gene_sim.data, gene_sim.targets, batch_size=None, verbose=0)\n",
    "print(net_LCT.test) # it will report [loss, accuracy]\n",
    "\n",
    "net_LCT.predict(gene_sim, model)\n",
    "net_LCT.plot_cm(gene_sim.classes, text=True) # confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help code: deployment\n",
    "\n",
    "... # remember to filter/manipulate VCF file in the same way you did for the simulations!\n",
    "\n",
    "print(model.predict(gene_LCT.data, batch_size=None)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
