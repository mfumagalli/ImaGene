{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using _ImaGene_\n",
    "\n",
    "This tutorial will show you how to perform a multiclass classification using _ImaGene_.\n",
    "In this example, our goal is to classify whether a given _locus_ is under positive selection or neutrally evolving with 3 classes of selection coefficient (0,200,400 in $2N_e$ units with $N_e=10000$) and we will be using the case of lactase persistence in European populations.\n",
    "\n",
    "Please refer to the tutorial for binary classification for an in-depth explanation of the case study and main steps of the pipeline.\n",
    "Here we will mostly focus on the main differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import _pickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pymc3\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers, activations, optimizers, regularizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import load_model\n",
    "\n",
    "import itertools\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pydot # optional, but required by keras to plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../ImaGene.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data from VCF file and store it into _ImaGene_ objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_LCT = ImaFile(nr_samples=198, VCF_file_name='LCT.CEU.vcf')\n",
    "gene_LCT = file_LCT.read_VCF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume we are unsure about the ancestral/derived polarisation and we switch labelling of alleles to major/minor.\n",
    "We also then retain all polymorphic sites and discard columns corresponding to sites with a sample minor allele frequency of 0 (a suitable threshold is 0.005 which is < 1/198)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.majorminor();\n",
    "gene_LCT.filter_freq(0.005);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dimensions and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.summary();\n",
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, we order rows based on their genetic distance from the most frequent haplotype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.sort('rows_dist');\n",
    "gene_LCT.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run and process simulations to be used for training the neural network\n",
    "\n",
    "We provide an example of parameter file called `params_multiclass` which simulates a total of 250,000 loci of 80kbp either under neutral evolution or positive selection with additive effect and allelic selection coefficients of 100, 200, 300, or 400 in $2N_e$ units with $N_e=10,000$.\n",
    "All other parameters are set as in the example of binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set as appropriate, e.g.:\n",
    "# path_sim='/home/mfumagal/Data/ImaGene/Tutorials/' # my local machine\n",
    "# path_sim='/mnt/quobyte/ImaGene/' # for workshop spp1819\n",
    "path_sim = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open, edit, save and class `params_multiclass.txt` file to specify directories and simulation parameters. Here I assume that simulations will be stored in `path+Multiclass/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wish to generate new training data, do not run otherwise\n",
    "import subprocess\n",
    "subprocess.call(\"bash ../generate_dataset.sh params_multiclass.txt\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an illustration, read the first batch of simulations to explore their content. Retain only 200 data points per class for a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sim = ImaFile(simulations_folder=path_sim + 'Multiclass/Simulations1', nr_samples=198, model_name='Marth-3epoch-CEU');\n",
    "gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=200);\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we have 1000 images (200 for each one of the 5 classes).\n",
    "The average number of columns is $\\approx 285$.\n",
    "\n",
    "We can check the sample allele frequency for the selected allele. Recall that we imposed selection to be acting in the middle of the region. Therefore, the targeted allele will be in position '0.5' in the _msms_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = calculate_allele_frequency(gene_sim, 0.5);\n",
    "plt.scatter(gene_sim.targets, freqs, marker='o');\n",
    "plt.xlabel('Selection coefficient');\n",
    "plt.ylabel('Allele frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same data processing as done for LCT. As an exmaple, we resize all images to the average dimensions of (198,285)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.majorminor();\n",
    "gene_sim.filter_freq(0.005);\n",
    "gene_sim.sort('rows_dist');\n",
    "gene_sim.resize((198,285));\n",
    "gene_sim.convert();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we are just interested in a classification of 3 classes: 0, 200, 400.\n",
    "For doing that, first we need to set `.classes` to the desired values and then we need to take a subset of the data corresponding to the desired classes only.\n",
    "We can achieve these steps with the following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sim.classes = np.array([0,200,400]);\n",
    "gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes));\n",
    "gene_sim.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 600 data points corresponding to the desired classes, as expected. \n",
    "\n",
    "### 3. Implement, train and evaluate the neural network\n",
    "\n",
    "As discussed in the tutorial on binary classification, we need to repeat this procedure across all batches of data leaving the last one for testing. We retain 1000 images per class as an illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i <= 10:\n",
    "\n",
    "    # simluations \n",
    "    file_sim = ImaFile(simulations_folder=path_sim+'Multiclass/Simulations' + str(i), nr_samples=198, model_name='Marth-3epoch-CEU')\n",
    "\n",
    "    gene_sim = file_sim.read_simulations(parameter_name='selection_coeff_hetero', max_nrepl=1000)\n",
    "    \n",
    "    # manipulate data:\n",
    "    # switch to major/minor allele polarisation\n",
    "    # filter our monomorphic sites\n",
    "    # sort rows by genetic distance\n",
    "    gene_sim.majorminor()\n",
    "    gene_sim.filter_freq(0.005)\n",
    "    gene_sim.sort('rows_dist')\n",
    "    gene_sim.resize((198, 285))\n",
    "    gene_sim.convert()\n",
    "    \n",
    "    # use only classes 0,200,400\n",
    "    gene_sim.classes = np.array([0,200,400])\n",
    "    gene_sim.subset(get_index_classes(gene_sim.targets, gene_sim.classes))\n",
    "\n",
    "    # randomise data\n",
    "    gene_sim.subset(get_index_random(gene_sim))\n",
    "\n",
    "    # convert targets to categorical data\n",
    "    gene_sim.targets = to_categorical(gene_sim.targets)\n",
    "    \n",
    "    # at first iteration we build the model \n",
    "    if i == 1:\n",
    "\n",
    "        model = models.Sequential([\n",
    "                    layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid', input_shape=gene_sim.data.shape[1:]),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005), padding='valid'),\n",
    "                    layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(units=128, activation='relu'),\n",
    "                    layers.Dense(units=len(gene_sim.classes), activation='softmax')])\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        net_LCT = ImaNet(name='[C32+P]+[C64+P]x2+D128')\n",
    "\n",
    "    # training for iterations from 1 to 9\n",
    "    if i < 10:\n",
    "        score = model.fit(gene_sim.data, gene_sim.targets, batch_size=32, epochs=1, verbose=0, validation_split=0.10)\n",
    "        net_LCT.update_scores(score)\n",
    "    else:\n",
    "        # testing for iteration 10\n",
    "        net_LCT.test = model.evaluate(gene_sim.data, gene_sim.targets, batch_size=None, verbose=0)\n",
    "        net_LCT.predict(gene_sim, model)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory where to save models, e.g. \n",
    "# path='/home/mfumagal/Data/ImaGene/Tutorials/Data/' # my local machine\n",
    "# path='./' # for workshop spp1819\n",
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final (trained) model\n",
    "model.save(path+'model.multi.h5');\n",
    "\n",
    "# save testing data\n",
    "gene_sim.save(path+'gene_sim.multi');\n",
    "\n",
    "# save network\n",
    "net_LCT.save(path+'net_LCT.multi');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the objects above\n",
    "model = load_model(path+'model.multi.h5');\n",
    "gene_sim = load_imagene(file=path+'gene_sim.multi');\n",
    "net_LCT = load_imanet(path+'net_LCT.multi');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the training\n",
    "net_LCT.plot_train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the testing results [loss, accuracy]\n",
    "print(net_LCT.test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a confusion matrix (on the last gene_sim object which represents the testing data)\n",
    "net_LCT.plot_cm(gene_sim.classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. deploy the trained network on your genomic data of interest\n",
    "\n",
    "Finally we use the trained network to predict the class of natural selection on our locus of interest.\n",
    "First we need to resize our real data to match the data used for training.\n",
    "After that, we need to convert the data into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_LCT.resize((198,285));\n",
    "gene_LCT.convert();\n",
    "gene_LCT.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this command will give us the class scores (0, 200, 400)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(gene_LCT.data, batch_size=None));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
